{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "486998d2",
   "metadata": {},
   "source": [
    "### Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d77d8b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df75ca0",
   "metadata": {},
   "source": [
    "### load ADN sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc9d0175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Notebook data challenge.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5333b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "870f6d01",
   "metadata": {},
   "source": [
    "### Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "177e4f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('Xtr_vectors.csv')\n",
    "X_test = pd.read_csv('Xte_vectors.csv')\n",
    "Y_train = pd.read_csv('Ytr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "de4e4cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1 = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3ce8023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = X_train.drop(\"Id\", axis = 1).values\n",
    "X_test_vec = X_test.drop(\"Id\", axis = 1).values\n",
    "Y_train_vec = Y_train.drop(\"Id\", axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "20ac937c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 64)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3422b68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c9c210",
   "metadata": {},
   "source": [
    "### Sequence embedding and data sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a5be8d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_to_dense(array):\n",
    "    return np.array(array.todense()) if issparse(array) else array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571937c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8120c17e",
   "metadata": {},
   "source": [
    "## kernels method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca466764",
   "metadata": {},
   "source": [
    "#### Ridge kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9ba53a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./heritiana.py\n"
     ]
    }
   ],
   "source": [
    "def linear_kernel(X1, X2):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    where K is the linear kernel\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    return sparse_to_dense(X1 @ X2.T)\n",
    "\n",
    "def polynomial_kernel(X1, X2, degree=3):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    where K is the polynomial kernel of degree `degree`\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    return (1 + linear_kernel(X1, X2))**degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9efa0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel(X1, X2, sigma=10):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    # For loop with rbf_kernel_element works but is slow in python\n",
    "    # Use matrix operations!\n",
    "    X2_norm = np.sum(X2 ** 2, axis = -1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis = -1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * sparse_to_dense(np.dot(X1, X2.T))))\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1e3f85fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47192770632799247\n"
     ]
    }
   ],
   "source": [
    "def sigma_from_median(X):\n",
    "    '''\n",
    "    Returns the median of ||Xi-Xj||\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    X: (n, p) matrix\n",
    "    '''\n",
    "#     euclidean_distances = np.linalg.norm(X, 1, axis = 1)\n",
    "    euclidean_distances = np.linalg.norm(X[:,None] - X, axis = 2).flatten()\n",
    "    return np.median(euclidean_distances)\n",
    "\n",
    "print(sigma_from_median(X_train_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8303e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRidge():\n",
    "    '''\n",
    "    Kernel Ridge Regression\n",
    "    \n",
    "    Methods\n",
    "    ----\n",
    "    fit\n",
    "    predict\n",
    "    '''\n",
    "    def __init__(self, sigma=None, lambd=0.1):\n",
    "        self.kernel = rbf_kernel\n",
    "        self.sigma = sigma\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        \n",
    "        # Compute default sigma from data\n",
    "        if self.sigma is None:\n",
    "            self.sigma = sigma_from_median(X)\n",
    "        \n",
    "        A = self.kernel(X, X, sigma=self.sigma) +  n*self.lambd * np.eye(n)\n",
    "        \n",
    "        ## self.alpha = (K + n lambda I)^-1 y\n",
    "        # Solution to A x = y\n",
    "        self.alpha = np.linalg.solve(A , y)\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # Prediction rule: \n",
    "        K_x = self.kernel(X, self.X_train, sigma=self.sigma)\n",
    "        return K_x @ self.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "214a58ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRidge_polynomial():\n",
    "    '''\n",
    "    Kernel Ridge Regression\n",
    "    \n",
    "    Methods\n",
    "    ----\n",
    "    fit\n",
    "    predict\n",
    "    '''\n",
    "    def __init__(self, sigma=None, lambd=0.1):\n",
    "        self.kernel = polynomial_kernel\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        \n",
    "        A = self.kernel(X, X, degree = 3) * np.eye(n)\n",
    "        \n",
    "        ## self.alpha = (K + n lambda I)^-1 y\n",
    "        # Solution to A x = y\n",
    "        self.alpha = np.linalg.solve(A , y)\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # Prediction rule: \n",
    "        K_x = self.kernel(X, self.X_train, degree = 3)\n",
    "        return K_x @ self.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "14f586a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KernelRidge(lambd=0.1, sigma = 0.01)\n",
    "y_pred = model.fit(X_train_vec, Y_train_vec)\n",
    "prediction = model.predict(X_test_vec)\n",
    "# prediction\n",
    "# print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "709a7f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KernelRidge_polynomial()\n",
    "y_pred_polynomial = model.fit(X_train_vec, Y_train_vec)\n",
    "prediction_polynomial = model.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a07860c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred,y_valid):\n",
    "    n= y_pred.shape[0]\n",
    "    good_pred = 0.0\n",
    "    for i in range(n):\n",
    "        if y_pred[i] == y_valid[i]:\n",
    "            good_pred +=1\n",
    "    return good_pred/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "4f4ee7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy(y_pred_polynomial, prediction_polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6bcf5be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accuracy(y_pred, y_valid):\n",
    "#     correct_pred = sum(y_pred == y_valid)\n",
    "#     return f\"The accuracy is :{correct_pred / len(y_valid) * 100.}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2182c0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.array([ 0 if p < 0.5 else 1 for p in prediction]).reshape(len(prediction),1)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08924d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "fe36eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iD = pd.DataFrame(x_test1.Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "96b796af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = np.array([ 0 if p <0.5 else 1 for p in prediction]).reshape(len(prediction), 1)\n",
    "# x_test = y_pred.rename(columns={0:\"Covid\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "ed8b0cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(y_pred, columns = [\"Covid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "8eb51c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(np.hstack([iD, pred]), columns = [\"Id\", \"Covid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "72309fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅✅✅✅✅✅✅\n"
     ]
    }
   ],
   "source": [
    "results.to_csv(\"prediction_for_Ridge_kernel.csv\",index=False)\n",
    "print(\"✅✅✅✅✅✅✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95224970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4249dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_polynomial = np.array([ 0 if p < 0.5 else 1 for p in prediction_polynomial]).reshape(len(prediction_polynomial),1)\n",
    "y_pred_polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1c092c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "iD = pd.DataFrame(x_test1.Id)\n",
    "pred = pd.DataFrame(y_pred_polynomial, columns = [\"Covid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "afb02942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅✅✅✅✅✅✅\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(np.hstack([iD, pred]), columns = [\"Id\", \"Covid\"])\n",
    "results.to_csv(\"prediction_for_Ridge_kernel_polynomial.csv\",index=False)\n",
    "\n",
    "print(\"✅✅✅✅✅✅✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c37b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c7c4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6b69375",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c294e0eb",
   "metadata": {},
   "source": [
    "#### Kernel method base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d67c532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelMethodBase(object):\n",
    "    '''\n",
    "    Base class for kernel methods models\n",
    "    \n",
    "    Methods\n",
    "    ----\n",
    "    fit\n",
    "    predict\n",
    "    fit_K\n",
    "    predict_K\n",
    "    '''\n",
    "    kernels_ = {\n",
    "        'linear': linear_kernel,\n",
    "        'polynomial': polynomial_kernel,\n",
    "        'rbf': rbf_kernel,\n",
    "        # 'mismatch': mismatch_kernel,\n",
    "    }\n",
    "    def __init__(self, kernel='linear', **kwargs):\n",
    "        self.kernel_name = kernel\n",
    "        self.kernel_function_ = self.kernels_[kernel]\n",
    "        self.kernel_parameters = self.get_kernel_parameters(**kwargs)\n",
    "        self.fit_intercept_ = False\n",
    "        \n",
    "    def get_kernel_parameters(self, **kwargs):\n",
    "        params = {}\n",
    "        if self.kernel_name == 'rbf':\n",
    "            params['sigma'] = kwargs.get('sigma', 1.)\n",
    "        if self.kernel_name == 'polynomial':\n",
    "            params['degree'] = kwargs.get('degree', 2)\n",
    "        return params\n",
    "\n",
    "    def fit_K(self, K, y, **kwargs):\n",
    "        pass\n",
    "        \n",
    "    def decision_function_K(self, K):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y, fit_intercept=False, **kwargs):\n",
    "\n",
    "        if fit_intercept:\n",
    "            X = add_column_ones(X)\n",
    "            self.fit_intercept_ = True\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "        K = self.kernel_function_(self.X_train, self.X_train, **self.kernel_parameters)\n",
    "\n",
    "        return self.fit_K(K, y, **kwargs)\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "\n",
    "        if self.fit_intercept_:\n",
    "            X = add_column_ones(X)\n",
    "\n",
    "        K_x = self.kernel_function_(X, self.X_train, **self.kernel_parameters)\n",
    "\n",
    "        return self.decision_function_K(K_x)\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    \n",
    "    def predict_K(self, K):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb94235",
   "metadata": {},
   "source": [
    "#### SVM kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7afacceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxopt\n",
    "\n",
    "def cvxopt_qp(P, q, G, h, A, b):\n",
    "    P = .5 * (P + P.T)\n",
    "    cvx_matrices = [\n",
    "        cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "    ]\n",
    "    #cvxopt.solvers.options['show_progress'] = False\n",
    "    solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "    return np.array(solution['x']).flatten()\n",
    "\n",
    "solve_qp = cvxopt_qp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "58cff2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K shape (2000, 2000)\n",
      "diag(y) shape (1,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1,) and (2000,2000) not aligned: 1 (dim 0) != 2000 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [140]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m P, q, G, h, A, b\n\u001b[1;32m     19\u001b[0m K \u001b[38;5;241m=\u001b[39m linear_kernel(X_train_vec, X_train_vec)\n\u001b[0;32m---> 20\u001b[0m alphas \u001b[38;5;241m=\u001b[39m solve_qp(\u001b[38;5;241m*\u001b[39m\u001b[43msvm_dual_soft_to_qp_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[0;32mIn [140]\u001b[0m, in \u001b[0;36msvm_dual_soft_to_qp_kernel\u001b[0;34m(K, y, C)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK shape\u001b[39m\u001b[38;5;124m\"\u001b[39m, K\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiag(y) shape\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mdiag(y)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 8\u001b[0m P \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiag\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdot(np\u001b[38;5;241m.\u001b[39mdiag(y))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# As a regularization, we add epsilon * identity to P\u001b[39;00m\n\u001b[1;32m     10\u001b[0m eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-12\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1,) and (2000,2000) not aligned: 1 (dim 0) != 2000 (dim 0)"
     ]
    }
   ],
   "source": [
    "def svm_dual_soft_to_qp_kernel(K, y, C=1):\n",
    "    n = K.shape[0]\n",
    "    assert (len(y) == n)\n",
    "        \n",
    "    # Dual formulation, soft margin\n",
    "    print(\"K shape\", K.shape)\n",
    "    print(\"diag(y) shape\", np.diag(y).shape)\n",
    "    P = np.diag(y).dot(K).dot(np.diag(y))\n",
    "    # As a regularization, we add epsilon * identity to P\n",
    "    eps = 1e-12\n",
    "    P += eps * np.eye(n)\n",
    "    q = - np.ones(n)\n",
    "    G = np.vstack([-np.eye(n), np.eye(n)])\n",
    "    h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
    "    A = y[np.newaxis, :]\n",
    "    b = np.array([0.])\n",
    "    return P, q, G, h, A, b\n",
    "\n",
    "K = linear_kernel(X_train_vec, X_train_vec)\n",
    "alphas = solve_qp(*svm_dual_soft_to_qp_kernel(K, Y_train_vec, C=1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f5dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVM(KernelMethodBase):\n",
    "    '''\n",
    "    Kernel SVM Classification\n",
    "    \n",
    "    Methods\n",
    "    ----\n",
    "    fit\n",
    "    predict\n",
    "    '''\n",
    "    def __init__(self, C=0.1, **kwargs):\n",
    "        self.C = C\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def fit_K(self, K, y, tol=1e-3):\n",
    "        # Solve dual problem\n",
    "        self.alpha = solve_qp(*svm_dual_soft_to_qp_kernel(K, y, C=self.C))\n",
    "        \n",
    "        # Compute support vectors and bias b\n",
    "        sv = np.logical_and((self.alpha > tol), (self.C - self.alpha > tol))\n",
    "        self.bias = y[sv] - K[sv].dot(self.alpha * y)\n",
    "        self.bias = self.bias.mean()\n",
    "\n",
    "        self.support_vector_indices = np.nonzero(sv)[0]\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def decision_function_K(self, K_x):\n",
    "        return K_x.dot(self.alpha * self.y_train) + self.bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.decision_function(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5733c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 'polynomial'\n",
    "sigma = 1.\n",
    "degree = 2\n",
    "C = 1.\n",
    "tol = 1e-3\n",
    "model = KernelSVM(C=C, kernel=kernel, sigma=sigma, degree=degree)\n",
    "y = model.fit(X_train, Y_train_vec, tol=tol).predict(X_test_vec)\n",
    "y_pred = model.predict(X_test_vec)\n",
    "print(\"✅✅✅✅✅✅✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a9a09",
   "metadata": {},
   "source": [
    "#### Kernel logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eabc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelLogisticRegression(KernelMethodBase):\n",
    "    '''\n",
    "    Kernel Logistic Regression\n",
    "    '''\n",
    "    def __init__(self, lambd=0.1, **kwargs):\n",
    "\n",
    "        self.lambd = lambd\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    \n",
    "    def fit_K(self, K, y, method='gradient', lr=0.1, max_iter=500, tol=1e-12):\n",
    "        '''\n",
    "        Find the dual variables alpha\n",
    "        '''\n",
    "        if method == 'gradient':\n",
    "            self.fit_alpha_gradient_(K, y, lr=lr, max_iter=max_iter, tol=tol)\n",
    "        elif method == 'newton':\n",
    "            self.fit_alpha_newton_(K, y, max_iter=max_iter, tol=tol)\n",
    "            \n",
    "        return self\n",
    "        \n",
    "    def fit_alpha_gradient_(self, K, y, lr=0.01, max_iter=500, tol=1e-6):\n",
    "        '''\n",
    "        Finds the alpha of logistic regression by gradient descent\n",
    "        \n",
    "        lr: learning rate\n",
    "        max_iter: Max number of iterations\n",
    "        tol: Tolerance wrt. optimal solution\n",
    "        '''\n",
    "        n = K.shape[0]\n",
    "        # Initialize\n",
    "        alpha = np.zeros(n)\n",
    "        # Iterate until convergence or max iterations\n",
    "        for n_iter in range(max_iter):\n",
    "            alpha_old = alpha\n",
    "            print(y.shape)\n",
    "            print(K.shape)\n",
    "            s = y * sigmoid(-y@(K*alpha_old))\n",
    "            gradient = -1/n * K@s + 2*lambd*K@alpha\n",
    "            alpha = alpha_old - lr * gradient\n",
    "            # Break condition (achieved convergence)\n",
    "            if np.sum((alpha-alpha_old)**2) < tol**2:\n",
    "                break\n",
    "        self.n_iter = n_iter\n",
    "        self.alpha = alpha\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        # return 1 / (1 + np.exp(-x))\n",
    "        # tanh version helps avoid overflow problems\n",
    "        return .5 * (1 + np.tanh(.5 * x))    \n",
    "    \n",
    "    def fit_alpha_newton_(self, K, y, max_iter=500, tol=1e-6):\n",
    "        '''\n",
    "        Finds the alpha of logistic regression by the Newton-Raphson method\n",
    "        and Iterated Least Squares\n",
    "        '''\n",
    "        n = K.shape[0]\n",
    "        # IRLS\n",
    "        KRR = KernelRidgeRegression(lambd=2*self.lambd)\n",
    "        # Initialize\n",
    "        alpha = np.zeros(n)\n",
    "        # Iterate until convergence or max iterations\n",
    "        for n_iter in range(max_iter):\n",
    "            alpha_old = alpha\n",
    "            m = K.dot(alpha_old)\n",
    "            w = sigmoid(m) * sigmoid(-m)\n",
    "            z = m + y / sigmoid(y * m)\n",
    "            alpha = KRR.fit_K(K, z, sample_weights=w).alpha\n",
    "            # Break condition (achieved convergence)\n",
    "            if np.sum((alpha-alpha_old)**2) < tol**2:\n",
    "                break\n",
    "        self.n_iter = n_iter\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def decision_function_K(self, K_x):\n",
    "        return sigmoid(K_x@self.alpha.T)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.sign(self.decision_function(X) -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21637337",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 'linear'\n",
    "sigma = .05\n",
    "lambd = .05\n",
    "degree = 3\n",
    "intercept = False\n",
    "\n",
    "kernel_parameters = {\n",
    "    'degree': 2,\n",
    "    'sigma': .5,\n",
    "}\n",
    "lambd = 1.\n",
    "\n",
    "training_parameters = {\n",
    "    'fit_intercept': False,\n",
    "    'lr': 0.01,\n",
    "    'method': 'gradient'\n",
    "}\n",
    "\n",
    "model = KernelLogisticRegression(lambd=lambd, kernel=kernel, **kernel_parameters)\n",
    "\n",
    "model.fit(X_train_vec, Y_train_vec, **training_parameters)\n",
    "\n",
    "y_pred = model.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3fe511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
